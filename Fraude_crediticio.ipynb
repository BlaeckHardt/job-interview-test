{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deteccion de fraude crediticio con machine learning** (Ricardo Bustos Carreón)\n",
    "Partimos de un conjunto de datos con 7300 entradas y 31 variables de las cuales 29 son desconocidas, dos conocidas y el tipo de variable. De estas entradas 7000 son transacciones normales y 300 son transacciones fraudulentas, nuestro proposito es aprender a identificar si una operacion es legal o fraudulenta dado que este tipo de operaciones cuestan tanto al cliente como a la empresa, por eso comenzamos con un analisis enfocado el machine learning.\n",
    "\n",
    "## **Analisis exploratorio de datos**\n",
    "Ya conocemos nuestras variables, procederemos al analisis. No podemos basar si una transaccion es fraudulenta en funcion de la media o maxima pues la distribución del valor monetario de todas las transacciones está muy sesgada. La gran mayoría de las transacciones son relativamente pequeñas y solo una pequeña fracción de las transacciones se acerca al máximo.\n\n",
    "Ahora, ¿Qué pasa con las distribuciones de clase? ¿Cuántas transacciones son fraudulentas y cuántas no lo son? Bueno, como podemos esperar, la mayoría de las transacciones no son fraudulentas (95.890%), mientras que solo el 4.110% fueron fraudulentas.\n",
    "Visualicemoslo ahora con nuestro algoritmo: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El data frame tiene 7300 filas y 31 columnas.\n",
      "         Var        V1        V2        V3  ...       V27       V28  Amount  Class\n",
      "1652  105397  1.287631  0.410746  0.151841  ...  0.030363  0.020647    6.95      0\n",
      "4902  129463  1.454601 -1.063245  0.440964  ...  0.021222  0.011972   25.00      0\n",
      "2568   15877  1.219136  0.535374 -0.482669  ... -0.041098  0.032509    0.76      0\n",
      "947   169560 -1.317357  1.609457 -1.498172  ...  0.273136 -0.035843    8.97      0\n",
      "839   233197  2.113497  0.575076 -2.803749  ...  0.023942 -0.002685    1.00      0\n",
      "\n",
      "[5 rows x 31 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7300 entries, 0 to 7299\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Var     7300 non-null   int64  \n",
      " 1   V1      7300 non-null   float64\n",
      " 2   V2      7300 non-null   float64\n",
      " 3   V3      7300 non-null   float64\n",
      " 4   V4      7300 non-null   float64\n",
      " 5   V5      7300 non-null   float64\n",
      " 6   V6      7300 non-null   float64\n",
      " 7   V7      7300 non-null   float64\n",
      " 8   V8      7300 non-null   float64\n",
      " 9   V9      7300 non-null   float64\n",
      " 10  V10     7300 non-null   float64\n",
      " 11  V11     7300 non-null   float64\n",
      " 12  V12     7300 non-null   float64\n",
      " 13  V13     7300 non-null   float64\n",
      " 14  V14     7300 non-null   float64\n",
      " 15  V15     7300 non-null   float64\n",
      " 16  V16     7300 non-null   float64\n",
      " 17  V17     7300 non-null   float64\n",
      " 18  V18     7300 non-null   float64\n",
      " 19  V19     7300 non-null   float64\n",
      " 20  V20     7300 non-null   float64\n",
      " 21  V21     7300 non-null   float64\n",
      " 22  V22     7300 non-null   float64\n",
      " 23  V23     7300 non-null   float64\n",
      " 24  V24     7300 non-null   float64\n",
      " 25  V25     7300 non-null   float64\n",
      " 26  V26     7300 non-null   float64\n",
      " 27  V27     7300 non-null   float64\n",
      " 28  V28     7300 non-null   float64\n",
      " 29  Amount  7300 non-null   float64\n",
      " 30  Class   7300 non-null   int64\n",  
      "dtypes: float64(29), int64(2)\n",
      "<h3 align='center'><img src='https://scontent.fmex5-1.fna.fbcdn.net/v/t39.30808-6/314893237_3266202983644348_7265197169524260051_n.jpg?_nc_cat=102&ccb=1-7&_nc_sid=730e14&_nc_eui2=AeF5Ym7Cti9j80lQig7x5DP4HVozU8ZUu08dWjNTxlS7Tyl8I7eCu8SBUu6dB4sNb8Tie0fnm1c_VFGjxTVqOF3q&_nc_ohc=TwtF7h29wdkAX9T6hJS&_nc_ht=scontent.fmex5-1.fna&oh=00_AfA6IRVKoQ7-pZ4uffR9yXwGPstZoTbfwy2XQEbG1mUMWQ&oe=636E4A9F' alt='python' width='400' height='400'>\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "df = pd.read_csv('C:/Users/ricar/Desktop/dataset.csv')\n",
    "print('El data frame tiene {} filas y {} columnas.'.format(df.shape[0], df.shape[1]))\n",
    "print (df.sample(5))\n",
    "print(df.info())\n",
    "\n",
    "df.loc[:, ['Var', 'Amount']].describe()\n",
    "#visualizacions de Var y amount\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Distribucion de la variable (Var)')\n",
    "sns.distplot(df.Var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h3 align='center'><img src='https://scontent.fmex5-1.fna.fbcdn.net/v/t39.30808-6/315073115_3266202986977681_5264328340428307278_n.jpg?_nc_cat=103&ccb=1-7&_nc_sid=730e14&_nc_eui2=AeHCI8zgQYdVlxaEPk_AKdCDOrmmh0a7JBA6uaaHRrskEDfKjKASta6857Q_LXz_f4a5VC5Ybgeq0s-UX0JQ-YaT&_nc_ohc=0cHt4AVji-oAX_jC2Z7&tn=iAnTb-G2baG76wTk&_nc_ht=scontent.fmex5-1.fna&oh=00_AfBkv1HGDFGEjdIcBsYaIPjchSRln8mzP1eV1sBzvovh9Q&oe=636F3A26' alt='python' width='400' height='400'>\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Distribucion del valor monetario (Amount)')\n",
    "sns.distplot(df.Amount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos 7000 transacciones normales (95.890%) y 300 transacciones fraudulentas (4.110%).\n",
      "<h3 align='center'><img src='https://scontent.fmex5-1.fna.fbcdn.net/v/t39.30808-6/314777348_3266202960311017_8811628485310736382_n.jpg?_nc_cat=102&ccb=1-7&_nc_sid=730e14&_nc_eui2=AeFndORm5pymB2H0mDyIuESrA2ZO7l_wIfUDZk7uX_Ah9YlVZz5OkRnKA7W0bqm4SK-eXg7RWcaIKwTJ_JpFqn1v&_nc_ohc=C8ZaVes1tUAAX8_UmA4&_nc_ht=scontent.fmex5-1.fna&oh=00_AfA5Ww79myRSh-6MYw045ZgwkqAVp4j2yowZ2iPnPvnMvg&oe=636EA2DE' alt='python' width='400' height='400'>\n"
     ]
    }
   ],
   "source": [
    "#Comparacion de transacciones fraudulentas contra normales\n",
    "counts = df.Class.value_counts()\n",
    "normal = counts[0]\n",
    "fraudulent = counts[1]\n",
    "perc_normal = (normal/(normal+fraudulent))*100\n",
    "perc_fraudulent = (fraudulent/(normal+fraudulent))*100\n",
    "print('Tenemos {} transacciones normales ({:.3f}%) y {} transacciones fraudulentas ({:.3f}%).'.format(normal, perc_normal, fraudulent, perc_fraudulent))\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=counts.index, y=counts)\n",
    "plt.title('Transacciones normales contra fraudulentas')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Class (0:Normales, 1:Fraudulentas)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos ahora la correlacion entre nuestras variables, para este caso usamos un mapa de calor, podemos apreciar una fuerte correlacion entre nuestras variables y las variables de clase.\n",
    "Visualicemos nuestro algoritmo: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Var        V1        V2  ...       V28    Amount     Class\n",
      "Var     1.000000  0.139439 -0.038180  ... -0.000669 -0.009194 -0.059608\n",
      "V1      0.139439  1.000000 -0.326759  ... -0.056911 -0.208454 -0.391060\n",
      "V2     -0.038180 -0.326759  1.000000  ... -0.052532 -0.501140  0.372244\n",
      "V3     -0.185765  0.484560 -0.408068  ... -0.039208 -0.147528 -0.569067\n",
      "V4     -0.125990 -0.279497  0.266135  ...  0.053758  0.095444  0.512064\n",
      "V5      0.184853  0.457110 -0.290087  ... -0.048134 -0.298085 -0.380176\n",
      "V6     -0.032212  0.089315 -0.135573  ...  0.062639  0.204001 -0.194888\n",
      "V7      0.116759  0.486588 -0.470636  ...  0.072419  0.247992 -0.527325\n",
      "V8     -0.069866 -0.071541  0.031140  ... -0.033491 -0.068391  0.093921\n",
      "V9      0.050420  0.263985 -0.250592  ...  0.035151 -0.024197 -0.399792\n",
      "V10     0.075346  0.420311 -0.359026  ...  0.020854 -0.070770 -0.622983\n",
      "V11    -0.230156 -0.300984  0.282850  ...  0.028729  0.016035  0.559960\n",
      "V12     0.130645  0.402597 -0.376569  ... -0.020242 -0.000617 -0.686879\n",
      "V13    -0.063115 -0.012954  0.010750  ...  0.014771  0.019868 -0.008057\n",
      "V14     0.016930  0.346429 -0.347768  ... -0.061900  0.023143 -0.745179\n",
      "V15    -0.191291  0.038567 -0.029814  ...  0.000797 -0.005513 -0.007546\n",
      "V16     0.074973  0.396511 -0.335107  ...  0.015371 -0.008550 -0.605122\n",
      "V17     0.051947  0.468831 -0.397873  ...  0.001536 -0.003592 -0.658189\n",
      "V18     0.125035  0.342541 -0.289528  ...  0.022519  0.024477 -0.430216\n",
      "V19     0.002151 -0.125755  0.091627  ...  0.012584 -0.047809  0.194352\n",
      "V20    -0.044795 -0.109643  0.004901  ... -0.070530  0.395129  0.075577\n",
      "V21    -0.001856 -0.037659  0.034218  ...  0.062427  0.099216  0.136412\n",
      "V22     0.121660 -0.007847  0.003364  ... -0.042209 -0.075112  0.019350\n",
      "V23     0.052965 -0.019138  0.036302  ... -0.124321 -0.162992 -0.001006\n",
      "V24    -0.010736 -0.022497 -0.002381  ...  0.024989  0.015432 -0.022442\n",
      "V25    -0.214930 -0.017198  0.038099  ... -0.017606 -0.110758  0.001027\n",
      "V26    -0.048627  0.011219  0.007860  ... -0.001511 -0.021555  0.006866\n",
      "V27    -0.036592  0.089717  0.009629  ...  0.040162 -0.006339  0.051615\n",
      "V28    -0.000669 -0.056911 -0.052532  ...  1.000000  0.101373  0.056108\n",
      "Amount -0.009194 -0.208454 -0.501140  ...  0.101373  1.000000  0.021524\n",
      "Class  -0.059608 -0.391060  0.372244  ...  0.056108  0.021524  1.000000\n",
      "\n",
      "[31 rows x 31 columns]\n",
      "Var        0.020035\n",
      "V1        -4.481444\n",
      "V2        -1.166526\n",
      "V3        -5.227091\n",
      "V4         1.673269\n",
      "V5        -4.156938\n",
      "V6         1.592675\n",
      "V7        -6.333446\n",
      "V8        -7.102290\n",
      "V9        -0.904524\n",
      "V10       -3.997582\n",
      "V11        2.196309\n",
      "V12       -4.851446\n",
      "V13        0.082059\n",
      "V14       -4.475472\n",
      "V15       -0.350468\n",
      "V16       -4.172801\n",
      "V17       -6.310052\n",
      "V18       -2.447589\n",
      "V19        0.399981\n",
      "V20        1.846739\n",
      "V21        6.780115\n",
      "V22       -0.660020\n",
      "V23       -1.468532\n",
      "V24       -0.582787\n",
      "V25       -0.471139\n",
      "V26        0.464624\n",
      "V27       -3.600876\n",
      "V28       12.924812\n",
      "Amount    18.509846\n",
      "Class      4.624390\n",
      "dtype: float64\n",
      "<h3 align='center'><img src='https://scontent.fmex5-1.fna.fbcdn.net/v/t39.30808-6/314994008_3266203003644346_7089088876615726276_n.jpg?_nc_cat=110&ccb=1-7&_nc_sid=730e14&_nc_eui2=AeG9QwqXt_Q6U6crevf8Sj5LWfhNwXZEqIVZ-E3BdkSohXYH9lbQ4tIaEAhl7obyyVEkzl8acUgFkbO1cKisvAIw&_nc_ohc=yElQnkHCudMAX9qnhdn&_nc_ht=scontent.fmex5-1.fna&oh=00_AfAuERME4HAOWPBKyVaIcs9HPP2ACrUO4tN2HXwB07BhPw&oe=636DDA4A' alt='python' width='400' height='400'>\n"
     ]
    }
   ],
   "source": [
    "corr = df.corr()\n",
    "print (corr)\n",
    "#Mapa de calor para visualización\n",
    "corr = df.corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "heat = sns.heatmap(data=corr)\n",
    "plt.title('Mapa de calor para correlacion')\n",
    "#Simetria\n",
    "skew_ = df.skew()\n",
    "print (skew_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deteccion de fraude crediticio con machine learning** (Ricardo Bustos Carreón)\n",
    "Partimos de un conjunto de datos con 7300 entradas y 31 variables de las cuales 29 son desconocidas, dos conocidas y el tipo de variable. De estas entradas 7000 son transacciones normales y 300 son transacciones fraudulentas, nuestro proposito es aprender a identificar si una operacion es legal o fraudulenta dado que este tipo de operaciones cuestan tanto al cliente como a la empresa, por eso comenzamos con un analisis enfocado el machine learning.\n",
    "\n",
    "## **Escalado de Var y Amount**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Var        V1        V2  ...  Class  scaled_amount  scaled_time\n",
      "5457  152309  2.051476 -0.328346  ...      0      -0.255451     0.131658\n",
      "3407  280439  2.035164 -0.139755  ...      0      -0.309429     1.686554\n",
      "441    79993 -1.710418  0.382147  ...      0      -0.309049    -0.745918\n",
      "1755  171772  2.199101 -0.795777  ...      0      -0.209114     0.367848\n",
      "7145   10497  1.189784  0.942289  ...      1      -0.299401    -1.589273\n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "#Escalado de cantidad (Amount) y (Var)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler2 = StandardScaler()\n",
    "#scalando Var\n",
    "scaled_time = scaler.fit_transform(df[['Var']])\n",
    "flat_list1 = [item for sublist in scaled_time.tolist() for item in sublist]\n",
    "scaled_time = pd.Series(flat_list1)\n",
    "#scalando la columnda de cantidad (amount)\n",
    "scaled_amount = scaler2.fit_transform(df[['Amount']])\n",
    "flat_list2 = [item for sublist in scaled_amount.tolist() for item in sublist]\n",
    "scaled_amount = pd.Series(flat_list2)\n",
    "#Concatenamos las columnas nuevas y el dataframe original\n",
    "df = pd.concat([df, scaled_amount.rename('scaled_amount'), scaled_time.rename('scaled_time')], axis=1)\n",
    "print(df.sample(5))\n",
    "#quitamos las columnas de amount y Var \n",
    "df.drop(['Amount','Var'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creando datos de entrenamiento y test** \n",
    "Para resolver este punto nos enfocaremos en realizar un muestreo inferior aleatorio para crear un conjunto de datos de entrenamiento con una distribución de clases equilibrada, asi obligaremos a los algoritmos a detectar transacciones fraudulentas como tales para lograr un alto rendimiento.\n\n",
    "Refiriendonos al rendimiento, vamos a hacer uso de las características de funcionamiento del receptor: área bajo la curva o medida de rendimiento ROC-AUC, escencialmente produce un valor entre cero y uno, por lo que uno es un puntaje perfecto y cero el peor. Entonces, si un algoritmo tiene un puntaje de más de 0.5, está logrando un mejor desempeño que las conjeturas al azar.\n",
    "Visualicemos nuestro algoritmo: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Separando informacion en train y test\n",
    "mask = np.random.rand(len(df)) < 0.9\n",
    "train = df[mask]\n",
    "test = df[~mask]\n",
    "print('Entrenamiento: {}\nTest: {}'.format(train.shape, test.shape))\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: (6547, 31)\n",
      "Test: (753, 31)\n",
      "Tenemos 267 transacciones fraudulentas en la data de entrenamiento.\n",
      "            V1        V2        V3  ...  Class  scaled_amount  scaled_time\n",
      "1201 -0.370695  0.817413  1.500371  ...      0      -0.269939    -1.687617\n",
      "3452  2.005876 -0.403021 -1.211072  ...      0      -0.213090     1.413304\n",
      "5189 -0.937393  0.710026 -0.237297  ...      0      -0.242068     0.673147\n",
      "2647  1.189597 -0.042003 -0.301652  ...      0      -0.050047    -0.144068\n",
      "1925  1.240280  0.002590 -1.331894  ...      0      -0.190925    -1.176442\n",
      "\n",
      "[5 rows x 31 columns]\n",
      "<h3 align='center'><img src='https://scontent.fmex5-1.fna.fbcdn.net/v/t39.30808-6/314846788_3266203073644339_2347546527326195984_n.jpg?_nc_cat=111&ccb=1-7&_nc_sid=730e14&_nc_eui2=AeHNLdZZIp1rWCZE2ne5JC4aooqy7jl6Iz6iirLuOXojPvEeaB_4LbS3AYS4QzLRISPi18m5QbjqtTKqPTcsukpz&_nc_ohc=Ncy57aAVe6kAX-Pzt67&_nc_ht=scontent.fmex5-1.fna&oh=00_AfCWmFqht2epNuyJbNH3XvoQ2WH5DDbTeaYQs6uTU5p1EQ&oe=636E9FF9' alt='python' width='400' height='400'>\n"
     ]
    }
   ],
   "source": [
    "#Creamos un subejemplo con distribuciones de clase balanceadas\n",
    "\n",
    "no_of_frauds = train.Class.value_counts()[1]\n",
    "print('Tenemos {} transacciones fraudulentas en la data de entrenamiento.'.format(no_of_frauds))\n",
    "#seleccionamos la cantidad equivalente de transacciones normales\n",
    "non_fraud = train[train['Class'] == 0]\n",
    "fraud = train[train['Class'] == 1]\n",
    "selected = non_fraud.sample(no_of_frauds)\n",
    "print(selected.head())\n",
    "#concatenamos ambas en una data de ejemplocon distribuciones de clase equivalente\n",
    "selected.reset_index(drop=True, inplace=True)\n",
    "fraud.reset_index(drop=True, inplace=True)\n",
    "subsample = pd.concat([selected, fraud])\n",
    "len(subsample)\n",
    "subsample = subsample.sample(frac=1).reset_index(drop=True)\n",
    "subsample.head(10)\n",
    "new_counts = subsample.Class.value_counts()\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=new_counts.index, y=new_counts)\n",
    "plt.title('Numero de transacciones fraudulentas contra normales en el ejemplo')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Class (0:Normales, 1:Fraudulentas)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Class\n",
      "V1            -0.435720\n",
      "V2             0.495217\n",
      "V3            -0.549128\n",
      "V4             0.716220\n",
      "V5            -0.415188\n",
      "V6            -0.384172\n",
      "V7            -0.491535\n",
      "V8             0.083490\n",
      "V9            -0.516827\n",
      "V10           -0.613859\n",
      "V11            0.680231\n",
      "V12           -0.666235\n",
      "V13           -0.027206\n",
      "V14           -0.738973\n",
      "V15           -0.003168\n",
      "V16           -0.599844\n",
      "V17           -0.566460\n",
      "V18           -0.479347\n",
      "V19            0.331789\n",
      "V20            0.125046\n",
      "V21            0.149468\n",
      "V22            0.014182\n",
      "V23            0.030585\n",
      "V24            0.044720\n",
      "V25            0.010432\n",
      "V26            0.032597\n",
      "V27            0.032605\n",
      "V28            0.130370\n",
      "Class          1.000000\n",
      "scaled_amount  0.008548\n",
      "scaled_time   -0.160106\n"
     ]
    }
   ],
   "source": [
    "#Veamos la correlacion una vez mas\n",
    "corr = subsample.corr()\n",
    "corr = corr[['Class']]\n",
    "print(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Class\n",
      "V3  -0.549128\n",
      "V9  -0.516827\n",
      "V10 -0.613859\n",
      "V12 -0.666235\n",
      "V14 -0.738973\n",
      "V16 -0.599844\n",
      "V17 -0.566460\n"
     ]
    }
   ],
   "source": [
    "#correlaciones negativas menores a -0.5\n",
    "print(corr[corr.Class < -0.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Class\n",
      "V4     0.716220\n",
      "V11    0.680231\n",
      "Class  1.000000\n"
     ]
    }
   ],
   "source": [
    "#correlaciones positivas mayores a 0.5\n",
    "print(corr[corr.Class > 0.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h3 align='center'><img src='https://scontent.fmex5-1.fna.fbcdn.net/v/t39.30808-6/314910474_3266203113644335_8104210165392035790_n.jpg?_nc_cat=107&ccb=1-7&_nc_sid=730e14&_nc_eui2=AeFaUQfvLJGQawdLqzRQoO7ycsH8Sn1PIT1ywfxKfU8hPVFXE7NGS_IE83KpuOuMUm2gFHF1IjEHTJNcTq9sMxZZ&_nc_ohc=7tGaDJqw2rAAX83Bj2W&_nc_ht=scontent.fmex5-1.fna&oh=00_AfA8ATpTuC5iAY_MtYuybM-pMltIrcCkSZp3TZUFNsP80w&oe=636DBD82' alt='python' width='400' height='400'>\n"
     ]
    }
   ],
   "source": [
    "#visualizando las variables con alta correlacion negativa\n",
    "f, axes = plt.subplots(nrows=2, ncols=4, figsize=(26,16))\n",
    "\n",
    "f.suptitle('variables con alta correlacion negativa', size=35)\n",
    "sns.boxplot(x='Class', y='V3', data=subsample, ax=axes[0,0])\n",
    "sns.boxplot(x='Class', y='V9', data=subsample, ax=axes[0,1])\n",
    "sns.boxplot(x='Class', y='V1', data=subsample, ax=axes[0,2])\n",
    "sns.boxplot(x='Class', y='V1', data=subsample, ax=axes[0,3])\n",
    "sns.boxplot(x='Class', y='V1', data=subsample, ax=axes[1,0])\n",
    "sns.boxplot(x='Class', y='V1', data=subsample, ax=axes[1,1])\n",
    "sns.boxplot(x='Class', y='V1', data=subsample, ax=axes[1,2])\n",
    "f.delaxes(axes[1,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h3 align='center'><img src='https://scontent.fmex23-1.fna.fbcdn.net/v/t39.30808-6/315003758_3266203110311002_8851833949373281310_n.jpg?_nc_cat=100&ccb=1-7&_nc_sid=730e14&_nc_eui2=AeH9gNpN3Kg5fLuKrKBXlAtPifWoE2FrEcyJ9agTYWsRzIPtHEs_DA_Ta6n6uXxjY0-p_7Vq7Hv0gabF9SXnb87Q&_nc_ohc=_BePVt0XNMsAX_eC1wu&_nc_ht=scontent.fmex23-1.fna&oh=00_AfA7lrnXUWwIbRnaNKO5X3xWbM_1DFXTKJ28u3xbQS6lDw&oe=636DE971' alt='python' width='400' height='400'>\n"
     ]
    }
   ],
   "source": [
    "#visualizando las variables con alta correlacion positiva\n",
    "f, axes = plt.subplots(nrows=1, ncols=2, figsize=(18,9))\n",
    "\n",
    "f.suptitle('variables con alta correlacion positiva', size=20)\n",
    "sns.boxplot(x='Class', y='V4', data=subsample, ax=axes[0])\n",
    "sns.boxplot(x='Class', y='V11', data=subsample, ax=axes[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terminamos con la eliminacion de variables atipicas, la reduccion de dimensionalidad y los algoritmos de clasificacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducimos nuestra data de 534 transacciones a 154 transacciones a 380 transacciones.\n",
      "X_shapes:\n",
      " X_train: X_validation:\n",
      " (304, 30) (76, 30) \n",
      "\n",
      "Y_shapes:\n",
      " Y_train: Y_validation:\n",
      " (304,) (76,)\n",
      "LR: 0.947495 (0.048584)\n",
      "LDA: 0.957383 (0.030403)\n",
      "KNN: 0.935032 (0.060732)\n",
      "CART: 0.862575 (0.060110)\n",
      "RF: 0.953353 (0.040278)\n",
      "<h3 align='center'><img src='https://scontent.fmex23-1.fna.fbcdn.net/v/t39.30808-6/315001427_3266203156977664_6113497219873285270_n.jpg?_nc_cat=103&ccb=1-7&_nc_sid=730e14&_nc_eui2=AeHZP5Go_xHqFJStX9VR2tbGZbDsyqtcBCNlsOzKq1wEI5f1RnuYiz_OAW0QqyCNp8eQxuF35x5VFknZ28XFKyZF&_nc_ohc=tah4Dko4bqQAX-J0Fk3&_nc_ht=scontent.fmex23-1.fna&oh=00_AfDhC0T2Ifq1FblKfGa1hfpwSgAdvF3UDXggKGz1syl_4A&oe=636EEFCC' alt='python' width='400' height='400'>\n",
      "<h3 align='center'><img src='https://scontent.fmex5-1.fna.fbcdn.net/v/t39.30808-6/314950798_3266202990311014_3964461776007888216_n.jpg?_nc_cat=102&ccb=1-7&_nc_sid=730e14&_nc_eui2=AeEbiilC5k2GRFi8262-540gF8SK3fhQaLEXxIrd-FBosRQI1ULMC_QfIbpt57mgRP7BTVy4dlfmrIZgxk6fE9Rj&_nc_ohc=rVSSyRRU0ZcAX-yKZlC&_nc_ht=scontent.fmex5-1.fna&oh=00_AfBtGcP37zYZT9DA_YqhY3ypkZwOWMUJae8J8FFqesMcgA&oe=636E3AF8' alt='python' width='400' height='400'>\n"
     ]
    }
   ],
   "source": [
    "#Eliminacion de variables atipicas extremas\n",
    "\n",
    "#Removiendo resultados atipicos\n",
    "Q1 = subsample.quantile(0.25)\n",
    "Q3 = subsample.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df2 = subsample[~((subsample < (Q1 - 2.5 * IQR)) |(subsample > (Q3 + 2.5 * IQR))).any(axis=1)]\n",
    "len_after = len(df2)\n",
    "len_before = len(subsample)\n",
    "len_difference = len(subsample) - len(df2)\n",
    "print('Reducimos nuestra data de {} transacciones a {} transacciones a {} transacciones.'.format(len_before, len_difference, len_after))\n",
    "\n",
    "#Reduccion de dimensionalidad\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X = df2.drop('Class', axis=1)\n",
    "y = df2['Class']\n",
    "#t-SNE\n",
    "X_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(X.values)\n",
    "# t-SNE scatter plot\n",
    "import matplotlib.patches as mpatches\n",
    "f, ax = plt.subplots(figsize=(24,16))\n",
    "blue_patch = mpatches.Patch(color='#0A0AFF', label='Normal')\n",
    "red_patch = mpatches.Patch(color='#AF0000', label='Fraude')\n",
    "\n",
    "ax.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\n",
    "ax.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)\n",
    "ax.set_title('t-SNE', fontsize=14)\n",
    "ax.grid(True)\n",
    "ax.legend(handles=[blue_patch, red_patch])\n",
    "\n",
    "#Algoritmos de clasificacion \n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "# train, test, split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.values\n",
    "X_validation = X_test.values\n",
    "y_train = y_train.values\n",
    "y_validation = y_test.values\n",
    "print('X_shapes:\n', 'X_train:', 'X_validation:\n', X_train.shape, X_validation.shape, '\n')\n",
    "print('Y_shapes:\n', 'Y_train:', 'Y_validation:\n', y_train.shape, y_validation.shape)\n",
    "\n",
    "#Algoritmos de verificacion lineal\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression())) #Regresion logistica\n",
    "models.append(('LDA', LinearDiscriminantAnalysis())) #Linear Discriminant Analysis\n",
    "models.append(('KNN', KNeighborsClassifier())) #KNN\n",
    "models.append(('CART', DecisionTreeClassifier())) #Decision tree\n",
    "models.append(('RF', RandomForestClassifier())) #Random forest\n",
    "#probando modelos\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: %f (%f)' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "#Comparando Algoritmos\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xticklabels(names)\n",
    "plt.title('Comparacion de algoritmos de clasificacion')\n",
    "plt.xlabel('Algoritmo')\n",
    "plt.ylabel('ROC-AUC Puntaje')\n",
    "plt.boxplot(results)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
